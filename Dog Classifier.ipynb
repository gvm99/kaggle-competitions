{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Preparing the path for dataset</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir dataset\n!mkdir dataset/yorkshire\n!mkdir dataset/beagle\n!mkdir dataset/pug\n!mkdir dataset/retriever\n!mkdir dataset/bulldog\n!mkdir dataset/rottweiler\n!mkdir dataset/pinscher\n!mkdir dataset/tzu","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Creating Functions and dealing with the images</h1>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport shutil\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\n\nnet = cv2.dnn.readNetFromCaffe(\"/kaggle/input/neuralnet/MobileNetSSD_deploy.prototxt.txt\", \"/kaggle/input/neuralnet/MobileNetSSD_deploy.caffemodel\")\ncategories = ['yorkshire','beagle','pug','retriever','bulldog','rottweiler','pinscher','tzu']\nimPath = 'dataset/yorkshire/n02094433_4028.jpg'\nCLASSES = [\"background\", \"aeroplane\", \"bicycle\", \"bird\", \"boat\",\n    \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\",\n    \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\",\n    \"sofa\", \"train\", \"tvmonitor\"]\n\ndef cropImage(imPath, destination):\n    im = cv2.imread(imPath)\n    blob = cv2.dnn.blobFromImage(cv2.resize(im, (300, 300)), 0.007843, (300, 300), 127.5)\n    net.setInput(blob)\n    detections = net.forward()\n    (h, w) = im.shape[:2]\n    for i in np.arange(0, detections.shape[2]):\n        confidence = detections[0, 0, i, 2]\n        idx = int(detections[0, 0, i, 1])\n        if CLASSES[idx] == 'dog' or CLASSES[idx] == 'cat':\n            if confidence > 0.5:\n                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n                (startX, startY, endX, endY) = box.astype(\"int\")\n                crop_img = im[startY:endY, startX:endX]\n                try:\n                    resized = cv2.resize(crop_img, (220,220), interpolation = cv2.INTER_AREA)\n                    if resized.shape != None:\n                        print(\"Salvo\",destination)\n                        cv2.imwrite(destination, resized)\n                except Exception as e:\n                    print(\"Erro\", e)\n        \ndef checkIfInCategories(categories, fileName):\n    for c in categories:\n        if c in fileName.lower():\n            return True, c\n    return False, None\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if '.jpg' in filename:\n            file = os.path.join(dirname,filename)\n            checked, fileDestination = checkIfInCategories(categories,file)\n            if checked:\n                destination = 'dataset/'+fileDestination+'/'+filename\n                cropImage(file,destination)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Transfer Learning with ResNet</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.keras.applications import ResNet50\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, GlobalAveragePooling2D\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n\nnum_classes = 8\nresnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nmy_new_model = Sequential()\nmy_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nmy_new_model.add(Dense(num_classes, activation='softmax'))\n\n# Say not to train first layer (ResNet) model. It is already trained\nmy_new_model.layers[0].trainable = False\n\nmy_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Preparing train dataset</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_size = 220\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = data_generator.flow_from_directory(\n        'dataset',\n        target_size=(image_size, image_size),\n        class_mode='categorical')\nanswers = tuple(zip(train_generator.class_indices.values(), train_generator.class_indices.keys()))\nmy_new_model.fit_generator(train_generator,steps_per_epoch=100,epochs=7)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<h1>Saving the model </h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_new_model.save('model.h5')","execution_count":37,"outputs":[{"output_type":"execute_result","execution_count":37,"data":{"text/plain":"((0, 'beagle'),\n (1, 'bulldog'),\n (2, 'pinscher'),\n (3, 'pug'),\n (4, 'retriever'),\n (5, 'rottweiler'),\n (6, 'tzu'),\n (7, 'yorkshire'))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'modelo_final.h5')","execution_count":16,"outputs":[{"output_type":"execute_result","execution_count":16,"data":{"text/plain":"/kaggle/working/kaggle/modelo_final.h5","text/html":"<a href='modelo_final.h5' target='_blank'>modelo_final.h5</a><br>"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}